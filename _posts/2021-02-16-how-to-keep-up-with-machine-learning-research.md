---
layout: post
title: "How to Keep Up with Machine Learning Research"
description: "A guide for how to the latest in machine learning research"
feature-img: "assets/img/rainbow.jpg"
thumbnail: "assets/img/boobook.jpg"
tags: [Deep Learning, Machine Learning]
---


I find it difficult to keep up with the latest in machine learning, even though it's part of my full-time job. Fortunately, there are a lot of resources out there to help sort through it all. I thought I would put together a list of resources that I use in case it helps anyone else. If you know of a great resource that I'm missing, please let me know!

<b>Table of contents</b>
* TOC
{:toc}

## Websites

[Arxiv Sanity](http://www.arxiv-sanity.com/)

* My #1 place to find new research
* Be sure to create an account and start saving papers you like so the recommendation feature can work
* Site created by Andrej Karpathy

[Papers with Code](https://paperswithcode.com/)
* The best site for seeing overall trends in the field
* Lots of new improvements that make this site better all the time
* There's also a newsletter (see below)

[Paper Digest](https://www.paperdigest.org/best-paper-digest/)
* Find the best papers from all the top conferences

[Google Scholar](https://scholar.google.com/)
* Start with a paper you're interested in and see who cited it

[ConnectedPapers](https://www.connectedpapers.com/)
* Creates a graph of papers, so you can find research that is similar the initial paper

## Newsletters

I'm not usually a newsletters guy, but for some reason, I've found that there are excellent newsletters in the machine learning world. Here are the ones I use:

[The Batch](https://www.deeplearning.ai/thebatch/)
* Newsletter by Andrew Ng and his company, [deeplearning.ai](https://www.deeplearning.ai/)
* Offers his thoughts on various hot topics, even if he is conspicuously anodyne
* Includes a mix of general ML news and research findings

[Import AI](https://jack-clark.net/)
* By Jack Clark of [OpenAI](https://openai.com/)
* Does a great job of highlighting the top papers of the week and gives good context for them as well
* [Subscribe here](https://us13.campaign-archive.com/home/?u=67bd06787e84d73db24fb0aa5&id=6c9d98ff2c)

[The Gradient](https://thegradientpub.substack.com/)
* Lots of good information on recent research

[Data Science Weekly](https://www.datascienceweekly.org/)

[Data Elixir](https://dataelixir.com/)
* One of my favorites

[Wild Week in AI](http://www.wildml.com/newsletter/)

[PapersWithCode](https://paperswithcode.com/newsletter/)


## YouTube

[Yannic Kilcher](https://www.youtube.com/c/YannicKilcher)
* Lots of videos, quite detailed paper reviews
* Most in the range of 20-60 minutes

[Two Minute Papers](https://www.youtube.com/c/K%C3%A1rolyZsolnai)
* Hold on to your papers because this guy is great
* Shortest videos (2-10 minutes) of them all

[Henry AI Labs](https://www.youtube.com/channel/UCHB9VepY6kYvZjj0Bgxnpbw)
* Not as popular as some of the others but still really good content

[Arxiv Insights](https://www.youtube.com/c/ArxivInsights)
* Not many videos but the ones he has are excellent

[The AI Epiphany](https://www.youtube.com/c/TheAIEpiphany)

[AI Coffee Break with Letitia](https://www.youtube.com/c/AICoffeeBreak)

## Textbooks

Recent textbooks can be a great place for learning the latest because they provide the necessary context. I've already written about textbooks so I'll just share the link to my [post on deep learning textbooks](https://jss367.github.io/free-deep-learning-textbooks.html).

## Podcasts

There are a lot of good podcasts about data science and machine learning. Unfortunately, they seem to come and go quickly. Some of my favorites are no longer active. Fortunately, there's a [website that tracks data science podcasts](https://dspods.netlify.app/) that is fairly exhaustive and generally kept up-to-date.

## Lectures

Sometimes I like to check out lectures to hear what I'm missing. Again, it's a good place to hear things in context. Here are some good ones.

[Deep Learning for Computer Vision at University of Michigan](https://www.youtube.com/playlist?list=PL5-TkQAfAZFbzxjBHtzdVCWE0Zbhomg7r)
* Taught by Justin Johnson, formerly of [CS231n](http://cs231n.stanford.edu/) fame

[fast.ai](https://www.fast.ai/)
* The instructor of the courses, Jeremy Howard, sometime references recent research in the lectures

## Blogs

I don't find as many helpful machine learning blogs as I would like. I'm sure there are more out there so I'll expand this list when I come across them. Let me know your favorites.

<https://karpathy.github.io/>

<https://rubikscode.net/blog/>

<https://ruder.io/>

<https://lilianweng.github.io/lil-log/>

<https://veredshwartz.blogspot.com/>

<https://huyenchip.com/blog/>

## Twitter

Twitter is probably not the best place to find the latest in machine learning research, but sometimes it's worth it. The lifecycle of people posting about ML before they get distracted by other topics seems pretty short, so I'm don't have any good recommendations at the moment. Feel free to look at [who I follow on Twitter](https://twitter.com/JuliusSimonelli/following) for some suggestions.
## Reddit

I don't go to reddit much for finding the latest in ML, but you can definitely find stuff there. Here are some of the subreddits I've subscribed to.

[r/MachineLearning](https://www.reddit.com/r/MachineLearning/)
* There's a weekly What Are You Reading (WAYR) pinned thread which can be good.

[r/computervision](https://www.reddit.com/r/computervision/)
* Not active as r/MachineLearning

There are some other subreddits but I don't use them very much.
